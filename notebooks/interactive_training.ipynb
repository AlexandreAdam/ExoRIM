{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExoRIM.model import RIM, CostFunction\n",
    "from ExoRIM.simulated_data import CenteredImagesv1\n",
    "from preprocessing.simulate_data import create_and_save_data\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aadam/Desktop/Projects/ExoRIM'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.split(os.getcwd())[0]\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-06-21_10-24-04'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#id = datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")\n",
    "id = \"20-06-21_10-24-04\"\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root, \"data\", id)\n",
    "if not os.path.isdir(data_dir): os.mkdir(data_dir)\n",
    "test_dir = os.path.join(root, \"data\", id + \"_test\")\n",
    "if not os.path.isdir(test_dir): os.mkdir(test_dir)\n",
    "projector_dir = os.path.join(root, \"data\", \"projector_arrays\")\n",
    "checkpoint_dir = os.path.join(root, \"models\", id)\n",
    "if not os.path.isdir(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "output_dir = os.path.join(root, \"results\", id)\n",
    "if not os.path.isdir(output_dir): os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': 12,\n",
       " 'pixels': 32,\n",
       " 'channels': 1,\n",
       " 'state_size': 16,\n",
       " 'state_depth': 32,\n",
       " 'Regularizer Amplitude': {'kernel': 0.01, 'bias': 0.01},\n",
       " 'Physical Model': {'Visibility Noise': 0.0001, 'Closure Phase Noise': 1e-05},\n",
       " 'Downsampling Block': [{'Conv_Downsample': {'kernel_size': [5, 5],\n",
       "    'filters': 1,\n",
       "    'strides': [2, 2]}}],\n",
       " 'Convolution Block': [{'Conv_1': {'kernel_size': [3, 3],\n",
       "    'filters': 8,\n",
       "    'strides': [1, 1]}},\n",
       "  {'Conv_2': {'kernel_size': [3, 3], 'filters': 16, 'strides': [1, 1]}}],\n",
       " 'Recurrent Block': {'GRU_1': {'kernel_size': [3, 3], 'filters': 16},\n",
       "  'Hidden_Conv_1': {'kernel_size': [3, 3], 'filters': 16},\n",
       "  'GRU_2': {'kernel_size': [3, 3], 'filters': 16}},\n",
       " 'Upsampling Block': [{'Conv_Fraction_Stride': {'kernel_size': [3, 3],\n",
       "    'filters': 16,\n",
       "    'strides': [2, 2]}}],\n",
       " 'Transposed Convolution Block': [{'TConv_1': {'kernel_size': [3, 3],\n",
       "    'filters': 8,\n",
       "    'strides': [1, 1]}},\n",
       "  {'TConv_2': {'kernel_size': [3, 3], 'filters': 1, 'strides': [1, 1]}}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(root, \"hyperparameters.json\"), \"r\") as f:\n",
    "    hparams = json.load(f)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "def create_dataset(meta_data, rim, dirname, batch_size=None):\n",
    "    images = tf.convert_to_tensor(create_and_save_data(dirname, meta_data), dtype=tf.float32)\n",
    "    k_images = rim.physical_model.simulate_noisy_image(images)\n",
    "    X = tf.data.Dataset.from_tensor_slices(k_images)  # split along batch dimension\n",
    "    Y = tf.data.Dataset.from_tensor_slices(images)\n",
    "    dataset = tf.data.Dataset.zip((X, Y))\n",
    "    if batch_size is not None: # for train set\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "        dataset = dataset.enumerate(start=0)\n",
    "        dataset = dataset.cache()  # accelerate the second and subsequent iterations over the dataset\n",
    "        dataset = dataset.prefetch(AUTOTUNE)  # Batch is prefetched by CPU while training on the previous batch occurs\n",
    "    else:\n",
    "        # batch together all examples, for test set\n",
    "        dataset = dataset.batch(images.shape[0], drop_remainder=True)\n",
    "        dataset = dataset.cache()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holes = 20\n",
    "# metrics only support grey scale images\n",
    "metrics = {\n",
    "    \"ssim\": lambda Y_pred, Y_true: tf.image.ssim(Y_pred, Y_true, max_val=1.0),\n",
    "    # Bug is tf 2.0.0, make sure filter size is small enough such that H/2**4 and W/2**4 >= filter size\n",
    "    # alternatively (since H/2**4 is = 1 in our case), it is possible to lower the power factors such that\n",
    "    # H/(2**(len(power factor)-1)) > filter size\n",
    "    # Hence, using 3 power factors with filter size=2 works, and so does 2 power factors with filter_size <= 8\n",
    "    # paper power factors are [0.0448, 0.2856, 0.3001, 0.2363, 0.1333]\n",
    "    # After test, it seems filter_size=11 also works with 2 power factors and 32 pixel image\n",
    "    \"ssim_multiscale_01\": lambda Y_pred, Y_true: tf.image.ssim_multiscale(\n",
    "        Y_pred, Y_true, max_val=1.0,\n",
    "        filter_size=11,\n",
    "        power_factors=[0.0448, 0.2856]),\n",
    "    \"ssim_multiscale_23\": lambda Y_pred, Y_true: tf.image.ssim_multiscale(\n",
    "        Y_pred, Y_true, max_val=1.0,\n",
    "        filter_size=11,\n",
    "        power_factors=[0.3001, 0.2363]),\n",
    "    \"ssim_multiscale_34\": lambda Y_pred, Y_true: tf.image.ssim_multiscale(\n",
    "        Y_pred, Y_true, max_val=1.0,\n",
    "        filter_size=11,\n",
    "        power_factors=[0.2363, 0.1333])\n",
    "}\n",
    "meta_data = CenteredImagesv1(total_items=1000, pixels=32)\n",
    "test_meta = CenteredImagesv1(total_items=200, pixels=32)\n",
    "cost_function = CostFunction()\n",
    "mask_coordinates = np.loadtxt(os.path.join(projector_dir, f\"mask_{holes}_holes.txt\"))\n",
    "with open(os.path.join(projector_dir, f\"projectors_{holes}_holes.pickle\"), \"rb\") as fb:\n",
    "    arrays = pickle.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = os.path.join(checkpoint_dir, \"rim_005_115.67728.h5\")\n",
    "rim = RIM(mask_coordinates=mask_coordinates, hyperparameters=hparams, arrays=arrays, weight_file=weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = rim.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    max_time=0.2,\n",
    "    cost_function=cost_function,\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    checkpoints=5,\n",
    "    output_dir=output_dir,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    max_epochs=20,\n",
    "    output_save_mod={\"index_mod\": 300,\n",
    "                     \"epoch_mod\": 1,\n",
    "                     \"step_mod\": 1}, # save first and last step imagees\n",
    "    metrics=metrics,\n",
    "    name=\"rim\"\n",
    ")\n",
    "end = time.time() - start\n",
    "with open(os.path.join(checkpoint_dir, \"hyperparameters.json\"), \"w\") as f:\n",
    "    json.dump(rim.hyperparameters, f)\n",
    "with open(os.path.join(output_dir, \"history.json\"), \"w\") as f:\n",
    "    json.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
